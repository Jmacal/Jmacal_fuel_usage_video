{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7383279-a742-41be-9371-9067fddf0447",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58715641-2aba-42c2-85a2-ed3f57ff5205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import folium\n",
    "from folium import plugins\n",
    "import numpy as np\n",
    "from folium import LayerControl as folium_LayerControl\n",
    "import csv\n",
    "import requests\n",
    "import json\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import time\n",
    "import imgkit\n",
    "from selenium import webdriver\n",
    "import moviepy\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import math\n",
    "from scipy.signal import savgol_filter\n",
    "from PIL import Image\n",
    "from moviepy.editor import VideoFileClip, CompositeVideoClip, concatenate_videoclips\n",
    "from moviepy.editor import clips_array\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a5e89c-d11a-4a23-a117-e64ae68b426b",
   "metadata": {},
   "source": [
    "## Organise log files into dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e779172c-7a28-4614-bc97-36d1b0f9c8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_sweep_sessions(csv_file_dir):\n",
    "    for file in os.listdir(csv_file_dir):\n",
    "        if os.path.isdir(os.path.join(csv_file_dir, file)):\n",
    "            continue\n",
    "        date = '_'.join(file.split('_')[1:4])\n",
    "        if not os.path.isdir(os.path.join(csv_file_dir, date)):\n",
    "            os.makedirs(os.path.join(csv_file_dir, date))\n",
    "        \n",
    "        shutil.move(os.path.join(csv_file_dir, file), os.path.join(csv_file_dir, date))\n",
    "        \n",
    "    print(\"Successfully sorted log files into dates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab8c511-fc9e-4699-9b9c-e34abe532bcd",
   "metadata": {},
   "source": [
    "## Convert log files to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1ec7cb7-496f-4aff-9d36-9cd09dea66df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_csv(input_data_dir, output_csv_dir):\n",
    "\n",
    "    try:\n",
    "        for file in os.listdir(input_data_dir):\n",
    "\n",
    "            if not os.path.exists(os.path.join(input_data_dir, file)):\n",
    "                print(f\"File {file} does not exist.\")\n",
    "                continue\n",
    "            elif os.path.exists(os.path.join(output_csv_dir, file[:-4]+'.csv')):\n",
    "                print(f\"CSV {file[:-4]+'.csv'} already exists.\")\n",
    "                continue\n",
    "            else:\n",
    "                columns = []\n",
    "                data = []\n",
    "                reading_data = False\n",
    "        \n",
    "                with open(os.path.join(input_data_dir, file), 'r') as data_file:\n",
    "                    for row in data_file:\n",
    "                        if row.split(' ')[0] == 'time' or row.split(' ')[0] == 'sats':\n",
    "                            columns = row.split(' ')\n",
    "                        elif row.split(']')[0] == '[data':\n",
    "                            reading_data = True\n",
    "                            continue\n",
    "        \n",
    "                        if reading_data:\n",
    "                            data_row = row.split(' ')\n",
    "                            data.append(data_row)\n",
    "        \n",
    "                with open(os.path.join(output_csv_dir, file[:-4]+'.csv'), 'w') as csv_file:\n",
    "                    csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "                    csv_writer.writerow(columns)\n",
    "                    for d_r in data:\n",
    "                        csv_writer.writerow(d_r)\n",
    "\n",
    "        print(\"Data files have been successfully converted to csv\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7ab542-6f28-46dc-bd14-66825e0b5c9e",
   "metadata": {},
   "source": [
    "## Modify csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0046006-3033-4430-8101-7fdd86012720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data_files(csv_data_dir, formatted_csv_path):\n",
    "\n",
    "    try:\n",
    "        for csv_file in os.listdir(csv_data_dir):\n",
    "\n",
    "            if not os.path.exists(os.path.join(csv_data_dir, csv_file)):\n",
    "                print(f\"File {csv_file} does not exist.\")\n",
    "                continue\n",
    "            elif os.path.exists(os.path.join(formatted_csv_path, csv_file)) or os.path.exists(os.path.join(formatted_csv_path, '_'.join(csv_file.split('_')[1:4]), csv_file)):\n",
    "                print(f\"File {csv_file} already formatted.\")\n",
    "                continue\n",
    "            else:\n",
    "\n",
    "                date = '-'.join(csv_file.split('.')[0].split('_')[1:4])\n",
    "                \n",
    "                df = pd.read_csv(os.path.join(csv_data_dir, csv_file))\n",
    "            \n",
    "                df['DateTime'] = date + ' ' + df['time']\n",
    "            \n",
    "                df.to_csv(os.path.join(formatted_csv_path, csv_file), index=False)\n",
    "\n",
    "        print(\"Csv files have been successfully formatted\")\n",
    "        return  True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a188d182-90d5-471c-bee9-0010e5115242",
   "metadata": {},
   "source": [
    "## Extract data values from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "095bf6fd-bcf7-4f3c-9901-44f00f81de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_values(formatted_csv_path):\n",
    "    try:\n",
    "        # Read the CSV file directly into a DataFrame\n",
    "        df = pd.read_csv(formatted_csv_path)\n",
    "\n",
    "        # Extract the required columns directly into numpy arrays\n",
    "        long_data = df['Longitude'].to_numpy()\n",
    "        lat_data = df['Latitude'].to_numpy()\n",
    "        fuel_rate_data = df['EngineFuelRateTMSCS'].to_numpy()\n",
    "        nozzle_down1_data = df['Nozzle1downTMSCS'].to_numpy()\n",
    "        nozzle_down2_data = df['Nozzle2downTMS'].to_numpy()\n",
    "\n",
    "        # Convert datetime strings to datetime objects\n",
    "        datetime_data = pd.to_datetime(df['DateTime'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "        print(\"Data has been successfully collated\")\n",
    "        return long_data, lat_data, datetime_data, fuel_rate_data, nozzle_down1_data, nozzle_down2_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return None, None, None, None, None, None, None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b608c1-37b8-4d92-8637-dc6b65fbea1a",
   "metadata": {},
   "source": [
    "## Snap longitude and latitude to nearest road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b7c8d4-8250-4584-a933-2d8ee6da5b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_to_road(lat_vals, lon_vals):\n",
    "    url = 'http://localhost:8002/trace_attributes'\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "\n",
    "    shape_arr = [{\"lat\": lat, \"lon\": lon} for lat, lon in zip(lat_vals, lon_vals)]\n",
    "\n",
    "    data = {\n",
    "        \"shape\": shape_arr,\n",
    "        \"costing\": \"auto\",\n",
    "        \"shape_match\": \"map_snap\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "\n",
    "        snapped_lat_vals = [point[\"lat\"] for point in response_json[\"matched_points\"]]\n",
    "        snapped_lon_vals = [point[\"lon\"] for point in response_json[\"matched_points\"]]\n",
    "\n",
    "        return snapped_lat_vals, snapped_lon_vals\n",
    "        \n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a87794-210e-4773-88ce-c9d09e31147d",
   "metadata": {},
   "source": [
    "## Convert rgb to hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "318e3f0d-7ceb-434e-824d-b92125c65f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_hex(r, g, b):\n",
    "    \"\"\"Convert RGB color to Hex color.\"\"\"\n",
    "    return \"#{:02x}{:02x}{:02x}\".format(r, g, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8381bdc1-b124-41fc-b806-3cf685cc76e2",
   "metadata": {},
   "source": [
    "## Get appropriate color for the given fuel rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50f7ce4c-5a00-4307-b0b4-337940592dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(x):\n",
    "    if x < 0.3:\n",
    "        # Transition from green to yellow\n",
    "        red = int(x / 0.3 * 255)\n",
    "        green = 255\n",
    "    elif x < 0.6:\n",
    "        # Transition from yellow to orange\n",
    "        red = 255\n",
    "        green = int((1 - (x - 0.3) / 0.3) * 255)\n",
    "    else:\n",
    "        # Transition from orange to red\n",
    "        red = 255\n",
    "        green = int((1 - (x - 0.6) / 0.4) * 165) # Adjusting for a more distinct orange\n",
    "    blue = 0 # Blue remains 0 throughout the transition\n",
    "    return [red, green, blue]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d73c89-1df5-44b2-a789-c220b8b88a6c",
   "metadata": {},
   "source": [
    "## Define color of path given the current fuel rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c85856ac-b762-4601-8b8f-4f7b7beabc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fuel_rate_color(fuel_rate, nozzle_down1_data, nozzle_down2_data, min_val, max_val):\n",
    "    # Convert nozzle_down1_data and nozzle_down2_data to float only once\n",
    "    nozzle_down1_float = float(nozzle_down1_data)\n",
    "    nozzle_down2_float = float(nozzle_down2_data)\n",
    "\n",
    "    # Check if either nozzle is down\n",
    "    if nozzle_down1_float == 1.0 or nozzle_down2_float == 1.0:\n",
    "        # Normalize fuel_rate\n",
    "        normalized_fuel_rate = (fuel_rate - min_val) / (max_val - min_val)\n",
    "        # Get color based on normalized fuel_rate\n",
    "        color = get_color(normalized_fuel_rate)\n",
    "        # Convert color to hexadecimal representation\n",
    "        color = rgb_to_hex(color[0], color[1], color[2])\n",
    "    else:\n",
    "        color = 'black'\n",
    "\n",
    "    return color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d83481-1fb0-40a7-9489-fd50c8fced36",
   "metadata": {},
   "source": [
    "## Uses API to snap to road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06faf708-7b1b-49cb-91d6-f1922671bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_lon_lat(long_values, lat_values):\n",
    "    if len(lat_values) < 16000:\n",
    "        lat_values, long_values = snap_to_road(lat_values, long_values)\n",
    "    else:\n",
    "        i = 0\n",
    "        while i < len(lat_values):\n",
    "            segment_length = min(16000, len(lat_values) - i)\n",
    "            segment_lat, segment_long = snap_to_road(lat_values[i:i+segment_length], long_values[i:i+segment_length])\n",
    "            lat_values[i:i+segment_length] = segment_lat\n",
    "            long_values[i:i+segment_length] = segment_long\n",
    "            i += segment_length\n",
    "\n",
    "    return long_values, lat_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d815ad-98aa-4208-afeb-c6135d7fe3f2",
   "metadata": {},
   "source": [
    "## Convert html map to png map frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7f47d9a-1c9f-4925-b40e-115de9e50f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_to_png(html_file_path, output_png_path):\n",
    "    # Set up Chrome WebDriver options\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')  # Run Chrome in headless mode\n",
    "    options.add_argument('--disable-gpu')  # Disable GPU acceleration (may speed up rendering)\n",
    "    options.add_argument('--no-sandbox')  # Disable sandbox for compatibility with Docker\n",
    "\n",
    "    # Create WebDriver using a context manager\n",
    "    with webdriver.Chrome(options=options) as driver:\n",
    "        try:\n",
    "            # Load the HTML file\n",
    "            driver.get('file://' + html_file_path)\n",
    "\n",
    "            # Wait for specific element to be visible (adjust according to your HTML content)\n",
    "            WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.TAG_NAME, 'body')))\n",
    "\n",
    "            # Capture screenshot and save as PNG\n",
    "            driver.save_screenshot(output_png_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b142232c-83b3-467e-aeed-931a58e6357a",
   "metadata": {},
   "source": [
    "## Create video from frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9032e790-453c-4fdb-8236-000170e96877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_from_images(image_folder, output_video, fps):\n",
    "    image_files = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\") or img.endswith(\".png\")]\n",
    "\n",
    "    # Open the first image to get dimensions\n",
    "    first_image = cv2.imread(os.path.join(image_folder, image_files[0]))\n",
    "    height, width, _ = first_image.shape\n",
    "\n",
    "    # Initialize video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "\n",
    "    try:\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(image_folder, image_file)\n",
    "            frame = cv2.imread(image_path)\n",
    "            video.write(frame)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "    finally:\n",
    "        # Release resources\n",
    "        cv2.destroyAllWindows()\n",
    "        video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f65b48-6bb4-4bb3-901e-a8d0af79595e",
   "metadata": {},
   "source": [
    "## Calculate velocity of truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b032d2a-5931-4f8e-bb70-869a9676e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ground_speed(lon_lat_t, prev_lon_lat_t):\n",
    "    # Validate input values to ensure they are within feasible and safe ranges\n",
    "    delta_lat = abs(float(lon_lat_t[1]) - float(prev_lon_lat_t[1]))\n",
    "    delta_lon = abs(float(lon_lat_t[0]) - float(prev_lon_lat_t[0]))\n",
    "    delta_t = abs((lon_lat_t[2] - prev_lon_lat_t[2]).total_seconds())\n",
    "\n",
    "    if not (-180 <= delta_lat <= 180 and -180 <= delta_lon <= 180):\n",
    "        raise ValueError(\"Latitude and longitude change must be between -180 and 180 degrees.\")\n",
    "    if delta_t <= 0:\n",
    "        raise ValueError(\"Time interval must be greater than zero.\")\n",
    "\n",
    "    # Earth's radius in kilometers (mean radius)\n",
    "    R = 6371.0\n",
    "\n",
    "    # Convert latitude and longitude from degrees to radians for calculation\n",
    "    delta_lat_rad = math.radians(delta_lat)\n",
    "    delta_lon_rad = math.radians(delta_lon)\n",
    "\n",
    "    # Equirectangular approximation calculation\n",
    "    x = delta_lon_rad * math.cos(math.radians((float(lon_lat_t[1]) + float(prev_lon_lat_t[1])) / 2.0))\n",
    "    y = delta_lat_rad\n",
    "    d = R * math.sqrt(x ** 2 + y ** 2) * 1000  # Distance in meters between the two points\n",
    "\n",
    "    # Speed calculation\n",
    "    speed_mps = d / delta_t\n",
    "\n",
    "    # Conversion to other units\n",
    "    speed_mph = speed_mps * 2.23694  # Conversion to miles per hour\n",
    "    speed_kph = speed_mps * 3.6      # Conversion to kilometers per hour\n",
    "\n",
    "    return speed_mps, speed_mph, speed_kph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a991075e-f9ac-4605-9171-dbc858691705",
   "metadata": {},
   "source": [
    "## Smooth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87162265-fec5-4f0f-9234-7bc7dee49fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_data(data, window_length, polyorder):\n",
    "    smoothed_data = savgol_filter(data, window_length, polyorder)\n",
    "    return smoothed_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ba84b0-b22e-4636-a7a5-6f91f21df907",
   "metadata": {},
   "source": [
    "## Get velocity of truck at each timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3384810e-deee-41bb-8b69-f9ac140c5b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_velocity_data(lon_data, lat_data, time_data):\n",
    "    \n",
    "    velocity_data = [0.0]  # Initial velocity\n",
    "    \n",
    "    \n",
    "    for i in range(1, len(time_data)):\n",
    "\n",
    "        if i >= 10:\n",
    "            prev_lon, prev_lat, prev_time = lon_data[i-10], lat_data[i-10], time_data[i-10]\n",
    "        else:\n",
    "            prev_lon, prev_lat, prev_time = lon_data[0], lat_data[0], time_data[0]\n",
    "        \n",
    "        # Get the current row of status information\n",
    "        lon, lat, curr_time = lon_data[i], lat_data[i], time_data[i]\n",
    "\n",
    "        # Calculate time difference\n",
    "        time_diff = (curr_time - prev_time).total_seconds()\n",
    "\n",
    "        if time_diff == 0:\n",
    "            # If time difference is zero, maintain previous velocity\n",
    "            velocity_data.append(velocity_data[-1])\n",
    "        else:\n",
    "            # Calculate ground speed\n",
    "            speed_mps, speed_mph, speed_kph = calculate_ground_speed([lon, lat, curr_time], [prev_lon, prev_lat, prev_time])\n",
    "            velocity_data.append(speed_mph)\n",
    "\n",
    "    return velocity_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50f89a5-a1f1-4a3d-aa35-6e67f552d843",
   "metadata": {},
   "source": [
    "## Plot Fuel rate and velocity over frame number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5642221-847b-4ce3-b951-0eac35e37f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_images(velocity_data, fuel_rate_data, graph_frames_dir, max_frames):\n",
    "    smoothed_velocity_data = smooth_data(velocity_data, window_length=300, polyorder=3)\n",
    "    smoothed_fuel_rate_data = smooth_data(fuel_rate_data, window_length=300, polyorder=3)\n",
    "\n",
    "    frame_numbers = np.arange(len(fuel_rate_data))\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Create figure and subplots\n",
    "        fig, ax1 = plt.subplots()\n",
    "\n",
    "        # Plot fuel rate on the first subplot\n",
    "        ax1.plot(frame_numbers, smoothed_fuel_rate_data, color='red')\n",
    "        ax1.set_xlabel('Frame Number')\n",
    "        ax1.set_ylabel('Fuel Rate', color='red')\n",
    "\n",
    "        # Create a second y-axis for velocity and plot it on the same subplot\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(frame_numbers, smoothed_velocity_data, color='blue')\n",
    "        ax2.set_ylabel('Velocity (mph)', color='blue')\n",
    "        \n",
    "        \n",
    "        for frame_number in frame_numbers:\n",
    "            \n",
    "            # Draw a vertical line at the current frame number\n",
    "            frame_line = ax1.axvline(x=frame_number, color='green', linestyle='--')\n",
    "\n",
    "            # Save the plot as a numbered PNG file\n",
    "            plt.savefig(os.path.join(graph_frames_dir, f'frame_{frame_number}.png'))\n",
    "\n",
    "            frame_line.remove()\n",
    "\n",
    "            if frame_number == max_frames:\n",
    "                break\n",
    "\n",
    "        # Close the plot to release memory\n",
    "        plt.close(fig)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        # Ensure plots are closed in case of exception\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce756eeb-5e99-4f78-b63b-49c2e08c7877",
   "metadata": {},
   "source": [
    "## Merge frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b29fc74-8d78-4b8e-80d2-09b63edd8425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_frames(map_frame_dir, graph_frame_dir, video_frame_dir, merged_frame_dir, num_of_frames, max_frames, electric):\n",
    "    for n in range(num_of_frames):\n",
    "        with Image.open(os.path.join(map_frame_dir, f'frame_{n}.png')) as map_frame, \\\n",
    "             Image.open(os.path.join(graph_frame_dir, f'frame_{n}.png')).resize(map_frame.size) as graph_frame:\n",
    " \n",
    "                if electric:\n",
    "                    video_frame = Image.open(os.path.join(video_frame_dir, 'left', f'frame_{n}.png')).resize((map_frame.width*2, map_frame.height*2)) \n",
    "    \n",
    "                    merged_frame = Image.new('RGB', (map_frame.width*3, map_frame.height*2))\n",
    "        \n",
    "                    merged_frame.paste(graph_frame, (map_frame.width*2, 0))\n",
    "                    merged_frame.paste(map_frame, (map_frame.width*2, map_frame.height))\n",
    "        \n",
    "                    merged_frame.paste(video_frame, (0, 0))\n",
    "                \n",
    "                else:\n",
    "                    video_frames = [Image.open(os.path.join(video_frame_dir, vid_dir, f'frame_{n}.png')).resize(map_frame.size) \n",
    "                                    for vid_dir in os.listdir(video_frame_dir)]\n",
    "        \n",
    "                    merged_frame = Image.new('RGB', (map_frame.width*3, map_frame.height*2))\n",
    "        \n",
    "                    merged_frame.paste(graph_frame, (map_frame.width*2, 0))\n",
    "                    merged_frame.paste(map_frame, (map_frame.width*2, map_frame.height))\n",
    "        \n",
    "                    merged_frame.paste(video_frames[0], (map_frame.width, 0))\n",
    "                    merged_frame.paste(video_frames[1], (map_frame.width, map_frame.height))\n",
    "                    merged_frame.paste(video_frames[2], (0, 0))\n",
    "                    merged_frame.paste(video_frames[3].rotate(90, expand=False), (0, map_frame.height))\n",
    "    \n",
    "                # Save the merged image\n",
    "                merged_frame.save(os.path.join(merged_frame_dir, f\"frame_{n}.png\"))\n",
    "\n",
    "        if n == max_frames:\n",
    "            break\n",
    "\n",
    "    print(\"Frames merged\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d945c036-e2f7-4330-bb6e-c43484bb520b",
   "metadata": {},
   "source": [
    "## Store frames of each sweeping video as PNGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "018fe9e7-ab2f-41d3-9eff-30d60a76e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, output_dir, max_frames):\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Open the video file\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    success, frame = video_capture.read()\n",
    "    frame_count = 0\n",
    "    \n",
    "    # Loop through the video frames\n",
    "    while success and frame_count <= max_frames:  # Use < instead of <= to save exactly max_frames\n",
    "        \n",
    "        # Save frame as PNG image\n",
    "        cv2.imwrite(f\"{output_dir}/frame_{frame_count}.png\", frame)\n",
    "        \n",
    "        # Read next frame\n",
    "        success, frame = video_capture.read()\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        \n",
    "\n",
    "    # Release the video capture object\n",
    "    video_capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c33af2-d6e0-4833-9c4b-2e3d3e43e5cc",
   "metadata": {},
   "source": [
    "## Add info to frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a46b77a-3d28-4dc5-9026-adc9156c7dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_info_to_frame(frame_path, frame_n, electric):\n",
    "\n",
    "    frame = Image.open(frame_path)\n",
    "\n",
    "    w, h = frame.size\n",
    "\n",
    "    frame_with_info = np.array(frame.copy())\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX  # Set font style\n",
    "    font_scale = 1  # Set font scale\n",
    "\n",
    "    # Loop twice for two different text styles (black and white)\n",
    "    for a in range(2):\n",
    "        # Set text style for the first iteration\n",
    "        if a == 0:\n",
    "            colours = (0, 0, 0)  # black\n",
    "            font_thickness = 12\n",
    "        # Set text style for the second iteration\n",
    "        else:\n",
    "            colours = (255, 255, 255)  # white\n",
    "            font_thickness = 3\n",
    "\n",
    "        if not electric:\n",
    "            cv2.putText(frame_with_info, f'Frame {frame_n}', (((w//3)+20), 40), font, font_scale, colours, font_thickness)\n",
    "            cv2.putText(frame_with_info, f'Frame {frame_n}', (20, ((h//2)+40)), font, font_scale, colours, font_thickness)\n",
    "            cv2.putText(frame_with_info, f'Frame {frame_n}', (((w//3)+20), ((h//2)+40)), font, font_scale, colours, font_thickness)\n",
    "\n",
    "            cv2.putText(frame_with_info, f'Right', (((w//3)+20), (h-20)), font, font_scale, colours, font_thickness)\n",
    "            cv2.putText(frame_with_info, f'Front', (20, ((h//2)-20)), font, font_scale, colours, font_thickness)\n",
    "            cv2.putText(frame_with_info, f'Back', (((w//3)+20), ((h//2)-20)), font, font_scale, colours, font_thickness)\n",
    "\n",
    "        cv2.putText(frame_with_info, f'Frame {frame_n}', (20, 40), font, font_scale, colours, font_thickness)\n",
    "    \n",
    "        cv2.putText(frame_with_info, f'Left', (20, (h-20)), font, font_scale, colours, font_thickness)\n",
    "        \n",
    "\n",
    "    os.remove(frame_path)\n",
    "    Image.fromarray(frame_with_info).save(frame_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7f469f-f5fe-4f01-b411-fbd631093f09",
   "metadata": {},
   "source": [
    "## Create dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d23b627-982f-498f-9367-2bc009a27117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory_if_not_exists(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3226d5-7420-4b87-88d1-5760ed6c64b3",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c335c2-90aa-4a5a-b99c-541c7ab2a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    base_dir = '/home/james/workspace/fuel_usage_video/mapping_data'\n",
    "    data_dir = os.path.join(base_dir, 'log_files')\n",
    "    csv_dir = os.path.join(base_dir, 'csv_data')\n",
    "    format_csv_dir = os.path.join(base_dir, 'format_csv_data')\n",
    "    map_frame_dir = os.path.join(base_dir, 'map_frames')\n",
    "    graph_frame_dir = os.path.join(base_dir, 'graph_frames')\n",
    "    merged_frame_dir = os.path.join(base_dir, 'merged_frames')\n",
    "    output_videos_dir = os.path.join(base_dir, 'created_videos')\n",
    "    sweeping_videos_dir = os.path.join(base_dir, 'videos')\n",
    "    video_frame_dir = os.path.join(base_dir, 'video_frames')\n",
    "    max_frames = 999999\n",
    "\n",
    "    # Delete and recreate necessary directories\n",
    "    for directory in [base_dir, data_dir, csv_dir, format_csv_dir, map_frame_dir, graph_frame_dir, merged_frame_dir, output_videos_dir, sweeping_videos_dir, video_frame_dir, map_image_dir]:\n",
    "        shutil.rmtree(directory, ignore_errors=True)\n",
    "        create_directory_if_not_exists(directory)\n",
    "\n",
    "    if data_to_csv(data_dir, csv_dir) == False:\n",
    "        exit()\n",
    "\n",
    "    if format_data_files(csv_dir, format_csv_dir) == False:\n",
    "        exit()\n",
    "\n",
    "\n",
    "    for format_csv in os.listdir(format_csv_dir):\n",
    "        \n",
    "        long_data, lat_data, datetime_data, fuel_rate_data, nozzle_down1_data, nozzle_down2_data = get_data_values(os.path.join(format_csv_dir, format_csv))\n",
    "\n",
    "        velocity_data = get_velocity_data(long_data, lat_data, datetime_data)\n",
    "\n",
    "        #create_graph_images(velocity_data, fuel_rate_data, graph_frame_dir, max_frames)\n",
    "        \n",
    "        long_data, lat_data = correct_lon_lat(long_data, lat_data)\n",
    "\n",
    "        max_fuel_rate = max(fuel_rate_data)\n",
    "        min_fuel_rate = min(fuel_rate_data)\n",
    "                                                                                                                   \n",
    "        plot_data = []\n",
    "\n",
    "        map  = folium.Map(\n",
    "                location=[np.array(lat_data).mean(),np.array(long_data).mean()],\n",
    "                tiles='openstreetmap',\n",
    "                zoom_start=18,\n",
    "                prefer_canvas=True,\n",
    "                zoom_control=False,\n",
    "            )\n",
    "\n",
    "        if os.path.isdir(os.path.join(map_frame_dir, format_csv)[:-4]):\n",
    "            continue\n",
    "        \n",
    "        for n in range(len(long_data)-1):\n",
    "\n",
    "            if n == 0 or [lat_data[n], long_data[n]] != [lat_data[n+1], long_data[n+1]]:\n",
    "            \n",
    "                folium.PolyLine([[lat_data[n], long_data[n]], [lat_data[n+1], long_data[n+1]]], \n",
    "                                color=get_fuel_rate_color(fuel_rate_data[n], nozzle_down1_data[n], nozzle_down2_data[n], min_fuel_rate, max_fuel_rate), \n",
    "                                weight=5).add_to(map)\n",
    "    \n",
    "                map.location = [lat_data[n+1], long_data[n+1]]\n",
    "            \n",
    "            map.save(f\"{map_frame_dir}/frame_{n}.html\")\n",
    "            html_to_png(f\"{map_frame_dir}/frame_{n}.html\", f\"{map_frame_dir}/frame_{n}.png\")    \n",
    "            os.remove(f\"{map_frame_dir}/frame_{n}.html\")   \n",
    "\n",
    "            if n == max_frames:\n",
    "                break\n",
    "\n",
    "        # merge_graph_map_frames_to_video(map_frame_dir, graph_frame_dir, merged_frame_dir, len(long_data), max_frames)\n",
    "        # create_video_from_images(merged_frame_dir, os.path.join(map_graph_video_dir, f\"{format_csv[:-4]}.mp4\"), fps=10)\n",
    "\n",
    "        for video_path in os.listdir(os.path.join(sweeping_videos_dir, format_csv[:-4])):\n",
    "\n",
    "            if video_path.split('.')[-1] != 'h264':\n",
    "                output_vid_frame_dir = os.path.join(video_frame_dir, video_path.split('_')[0])\n",
    "                electric = False\n",
    "            else:\n",
    "                output_vid_frame_dir = os.path.join(video_frame_dir, 'left')\n",
    "                electric = True\n",
    "    \n",
    "            extract_frames(os.path.join(sweeping_videos_dir, format_csv[:-4], video_path), output_vid_frame_dir, max_frames)\n",
    "\n",
    "        merge_frames(map_frame_dir, graph_frame_dir, video_frame_dir, merged_frame_dir, len(long_data), max_frames, electric)\n",
    "        \n",
    "\n",
    "        for frame in os.listdir(merged_frame_dir):\n",
    "            add_info_to_frame(os.path.join(merged_frame_dir, frame), int(frame.split('_')[1].split('.')[0]), electric)\n",
    "\n",
    "        create_video_from_images(merged_frame_dir, os.path.join(output_videos_dir, f\"{format_csv[:-4]}.mp4\"), fps=10)\n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b14c0d-08c1-4872-864a-62480425ad14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
